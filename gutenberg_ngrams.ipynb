{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gutenberg N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the spark environment can be a bit of a trial and error procedure. Often you'll need to configure settings (in particular dealing with memory) to fit your cluster and your particular application. Below, we will specify a few of the most important ones -- but you can see the full list in the [Spark Configuration guide](http://spark.apache.org/docs/latest/configuration.html) and if you are using YARN there are critical options also listed under the [YARN deployment guide](http://spark.apache.org/docs/latest/running-on-yarn.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory allocated to the Spark driver is often an insignificant parameter, but it your driver ends up having to handle a lot of data (i.e. in large reduces or if it collects subsamples of the dataset) then this could be important. With the YARN scheduler, it's not very obvious how to specify this value nicely, but using the environment variable seems to work. Note that this has to be done *before* importing the `pyspark` package. Once this is set and the `pyspark` package imported, you may need to restart the python kernel if you want to make a change. You can see how much memory has been allocated to the driver either in the Spark Web UI or in the messages printed to the console at initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['SPARK_DRIVER_MEMORY'] = '8g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing `SparkConf` \n",
    "When starting the Spark runtime through the notebook or inside a script (i.e. when not calling one of the spark scripts like `spark_submit`), you can create a `SparkConf` object that allows you to set up the runtime. This is quite convenient and much more clean and readable than specifying the options on the commandline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put the number of executors and cores into variables so we can refer to it later\n",
    "num_execs = 20\n",
    "exec_cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing the SparkConf\n",
    "conf = SparkConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor options\n",
    "\n",
    "The full list of options is very long, but the basic ones you'll *always* want to at least think about are ones pertaining to the basic configuration of the executors: number of executors, memory per executor, and number of cores per executor. \n",
    "\n",
    "A few notes about the memory configuration: the `spark.executor.memory` should not be set to the total memory of the node. Some memory is needed for the OS (including HDFS and other services), and still more is required for the Spark overhead. So in our case here, we have 16 Gb of memory per node but can only use around 12 Gb of this for the executors. Since we need to leave room for 10% YARN overhead, we specify 9 Gb here to be safe. If your executors start dying off for strange reasons, try reducing the memory here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x2b36b2f1cc90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set('spark.executor.memory', '9g')\n",
    "conf.set('spark.executor.instances', str(num_execs))\n",
    "conf.set('spark.executor.cores', str(exec_cores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory configuration\n",
    "\n",
    "Two other key memory options exist, specifying the amount of executor memory reserved for *cached* data and for *shuffle* data. Depending on what your application is doing, you may need more of one or the other. For example, if you are running a lot of iterative operations on a large dataset, you probably want a good amount of memory for RDD caching. On the other hand, if you are doing lots of expensive shuffles that occur when sorting of grouping by key, you may want more shuffle memory. Note that if either one starts to run low, your application won't crash it will simply spill to disk. This usually isn't as bad as it sounds especially if the OS file cache kicks in. \n",
    "\n",
    "You can check on the cache memory and shuffle memory in two ways while your application is running. In the Spark UI, you can see the cached RDDs under the `Storage` tab - if they start spilling to disk, this is where you will see it. Similarly, if you are running a large shuffle job, you can click on the stage details in the Spark UI and see the shuffle memory and disk statistics. We will check on both of these later on in this application. \n",
    "\n",
    "Here we will set these two options explicitly for completeness, but actually keep the values at their defaults (60%  of the heap for caching, 20% for shuffles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x2b36b2f1cc90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set('spark.storage.memoryFraction', 0.6)\n",
    "conf.set('spark.shuffle.memoryFraction', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, just to make sure, specify the driver memory also here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x2b36b2f1cc90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set('spark.driver.memory', '8g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python libraries\n",
    "\n",
    "In some cases we need to tell the executors explicitly where the non-standard python libraries are located (this includes the spark libraries and seems to be new in Spark 1.4.0 -- a bug?). For this, we set the environment variable `PYTHONPATH`. Any other environment variable can be specified in this way, should it be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x2b36b2f1cc90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set('spark.executorEnv.PYTHONPATH', \n",
    "         '/cluster/apps/spark/spark-1.4.0-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip:/cluster/apps/spark/spark-1.4.0-bin-hadoop2.6/python/:/cluster/home03/sdid/roskarr/spark_workshop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the `SparkContext`\n",
    "This is our entry point to the Spark runtime - it is used to push data into spark or load RDDs from disk etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(master = 'yarn-client', conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a key-value RDD of book metadata and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data into spark from a collection of local files is a very common task. A useful pattern to keep in mind is the following: \n",
    "\n",
    "1. make a list of filenames and distribute it among the workers\n",
    "3. \"map\" each filename to the data you want to get out\n",
    "4. now you are left with the RDD of raw data distributed among the workers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`gutenberg_cleanup`](gutenberg_cleanup.py) module contains two functions that can help with this: `get_text` and `get_metadata`.\n",
    "\n",
    "They pretty much do the obvious: \n",
    "\n",
    "`get_metadata` returns a metadata object with various useful fields that will be used to create a unique key for each book\n",
    "\n",
    "`get_text` returns the raw text extracted from HTML, cleaned of tags and punctuation and converted to lower case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the raw dataset using `sc.parallelize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of books:  13963\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "flist = glob.glob('/cluster/home03/sdid/roskarr/work/gutenberg/html/*html')\n",
    "print 'number of books: ', len(flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use `sc.parallelize` to distribute a dataset across the cluster, you can choose the number of partitions across which to distribute the dataset. The higher the number of partitions, the higher the \"parallelism\". When Spark subsequently executes maps and reduces on this dataset, it does so by dispatching tasks to different executors, which then request the cores under their control to do the actual work. By increasing the number of partitions, you increase the number of tasks - more tasks gives the Spark scheduler more flexibility in distributing the work across the cluster and therefore maximally leveraging the compute resources at its disposal. In some cases, where a single partition might require a lot of memory it can cause `Out of memory` errors - in such cases, simply reducing the amount of data per task by increasing the parallelism can help. \n",
    "\n",
    "Note that the latency of scheduling is pretty low - as long as tasks take a few hundred milliseconds the scheduler should have no trouble dispatching them. On the other hand, there is a bit of overhead associated with partitioning the data so you don't want an unreasonably high number of partitions. You can see the [Spark guide](http://spark.apache.org/docs/latest/tuning.html#level-of-parallelism) for a bit more detail. \n",
    "\n",
    "Below, we will choose to use 5 times as many partitions as we have cores in the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_rdd = sc.parallelize(flist, num_execs*exec_cores*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cluster/home03/sdid/roskarr/work/gutenberg/html/1000.html',\n",
       " '/cluster/home03/sdid/roskarr/work/gutenberg/html/1001.html',\n",
       " '/cluster/home03/sdid/roskarr/work/gutenberg/html/1002.html',\n",
       " '/cluster/home03/sdid/roskarr/work/gutenberg/html/1003.html',\n",
       " '/cluster/home03/sdid/roskarr/work/gutenberg/html/1004.html']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the list of filenames into `key,value` pair RDD of metadata and text\n",
    "\n",
    "Use the `get_text` and `get_metadata` functions to construct a key,value pair RDD, where `key` is the dictionary returned by `get_metadata`. For the `value` of each `key`,`value` pair use the raw text returned by `get_text`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gutenberg_cleanup\n",
    "reload(gutenberg_cleanup)\n",
    "from gutenberg_cleanup import get_metadata, get_text, get_gid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_rdd = (files_rdd.map(lambda filename: (get_metadata(get_gid(filename)), get_text(filename))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we don't have to constantly re-load the data off disk, lets cache this RDD: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 ms, sys: 8 ms, total: 51 ms\n",
      "Wall time: 47.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_rdd.cache()\n",
    "text_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, we could call the native python `map` in exactly the same way, though this would take much longer to complete, i.e. \n",
    "\n",
    "    text = map(lambda f: (get_metadata(get_gid(f)), get_text(f)),flist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "UI_url": {}
    }
   },
   "source": [
    "Since we called `count()`, it means that the entire RDD was generated/calculated. This combination of `cache` and `count` is a common way to check how much memory your dataset needs - once `count` completes you can check the memory taken up by the RDD by going to the \"Storage\" tag of the Spark UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the meta-data in a dictionary for later use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_dict = dict()\n",
    "for meta in text_rdd.keys().collect() :\n",
    "    meta_dict[meta['gid']] = {key: meta[key] for key in ['gid', 'birth_year', 'death_year', 'first_name', 'last_name', 'title']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a look-up table that allows us to quickly access all the metadata indexed by `gid`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'birth_year': u'1954',\n",
       " 'death_year': None,\n",
       " 'first_name': u'Bruce',\n",
       " 'gid': 101,\n",
       " 'last_name': u'Sterling',\n",
       " 'title': u'The Hacker Crackdown: Law and Disorder on the Electronic Frontier'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dict[101]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need this lookup table later on in the analysis. Since it will be used in many `map` transformations, we would have to send it across the wire every time we used it. Alternatively, we could read the metadata off the disk every time, but this is even worse for many reasons. \n",
    "\n",
    "Instead, Spark offers us a [broadcast variable](http://spark.apache.org/docs/latest/programming-guide.html#broadcast-variables) mechanism. This allows us to distribute a non-trivial piece of data to all nodes and keep it there. When the code running on the nodes needs a value from the broadcast variable, it is simply grabbed from memory. Since the variable is stored in the JVM on the executor, if the executor runs many cores, those cores can share the data therefore even further reducing unnecessary network traffic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_b = sc.broadcast(meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying data object stored in `meta_b` can be accessed simply by\n",
    "\n",
    "    > meta_b.value\n",
    "    \n",
    "We'll make use of this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the raw dataset to HDFS \n",
    "We don't want to have to read the data off local disk every time we need to repeat some part of the analysis. Instead, it's much more advantageous to use the Hadoop Distributed File System (HDFS) to store the data once we've read it in and put it in a `key,value` format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_rdd.saveAsPickleFile('/user/roskarr/gutenberg/raw_text_rdd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, whenever we need it, we can read the data off the HDFS instead: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_text_rdd = sc.pickleFile('/user/roskarr/gutenberg/raw_text_rdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 ms, sys: 6 ms, total: 46 ms\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13963"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time loaded_text_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this read time to nearly two minutes it took to read it off the local filesystem initially. If you look at the details for this stage in the Spark UI you can understand why this is: in the column named \"locality level\", you see that for many tasks it says `NODE LOCAL` while for others it might say `RACK LOCAL`. These mean that either the data chunk was physically present on the disk of the node that was reading it in (`NODE LOCAL`) or it was on one of the nodes on the same switch (`RACK LOCAL`). Of course the additional advantage is not having to deal with the filesystem overhead of 10k+ small files.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data with filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to do some quality checks on the data. Let's check out the first couple of metadata entries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'birth_year': None,\n",
       "  'death_year': None,\n",
       "  'first_name': None,\n",
       "  'gid': 1000,\n",
       "  'last_name': None,\n",
       "  'title': '- No Title -'},\n",
       " {'birth_year': u'1265',\n",
       "  'death_year': u'1321',\n",
       "  'first_name': None,\n",
       "  'gid': 1001,\n",
       "  'last_name': u'Dante Alighieri',\n",
       "  'title': u\"Divine Comedy, Longfellow's Translation, Hell\"},\n",
       " {'birth_year': u'1807',\n",
       "  'death_year': u'1882',\n",
       "  'first_name': None,\n",
       "  'gid': 1002,\n",
       "  'last_name': u'Dante Alighieri',\n",
       "  'title': u\"Divine Comedy, Longfellow's Translation, Purgatory\"},\n",
       " {'birth_year': u'1265',\n",
       "  'death_year': u'1321',\n",
       "  'first_name': None,\n",
       "  'gid': 1003,\n",
       "  'last_name': u'Dante Alighieri',\n",
       "  'title': u\"Divine Comedy, Longfellow's Translation, Paradise\"},\n",
       " {'birth_year': u'1807',\n",
       "  'death_year': u'1882',\n",
       "  'first_name': None,\n",
       "  'gid': 1004,\n",
       "  'last_name': u'Dante Alighieri',\n",
       "  'title': u\"Divine Comedy, Longfellow's Translation, Complete\"}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.keys().take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at just the first few entries it becomes clear that we're going to have to do some quality control here. For example, we probably don't want books with \"None\" as either of the author names, and likewise we have to have the birth date in order to be able to create a time series out of the data in the end. \n",
    "\n",
    "Construct an RDD, as above, except that you filter out all the elements that have `None` for `title`, `first_name`, `last_name`, or `birth_year`. In addition, filter out the data with \"BC\" in either birth or death year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_func(meta) : \n",
    "    no_none = all([meta[name] is not None for name in ['title', 'first_name', 'last_name', 'birth_year']])\n",
    "    if not no_none : \n",
    "        return False\n",
    "    else : \n",
    "        no_birth_bc = 'BC' not in meta['birth_year']\n",
    "        no_death_bc = True if meta['death_year'] is None else 'BC' not in meta['death_year']\n",
    "        return no_birth_bc + no_death_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_rdd = text_rdd.filter(lambda (meta, text): filter_func(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'birth_year': u'1954',\n",
       " 'death_year': None,\n",
       " 'first_name': u'Bruce',\n",
       " 'gid': 101,\n",
       " 'last_name': u'Sterling',\n",
       " 'title': u'The Hacker Crackdown: Law and Disorder on the Electronic Frontier'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rdd.keys().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'birth_year': u'1954',\n",
       "  'death_year': None,\n",
       "  'first_name': u'Bruce',\n",
       "  'gid': 101,\n",
       "  'last_name': u'Sterling',\n",
       "  'title': u'The Hacker Crackdown: Law and Disorder on the Electronic Frontier'},\n",
       " {'birth_year': u'1866',\n",
       "  'death_year': u'1946',\n",
       "  'first_name': u'H. G. (Herbert George)',\n",
       "  'gid': 1013,\n",
       "  'last_name': u'Wells',\n",
       "  'title': u'The First Men in the Moon'},\n",
       " {'birth_year': u'1874',\n",
       "  'death_year': u'1940',\n",
       "  'first_name': u'B. M.',\n",
       "  'gid': 1014,\n",
       "  'last_name': u'Bower',\n",
       "  'title': u'The Lure of the Dim Trails'},\n",
       " {'birth_year': u'1823',\n",
       "  'death_year': u'1893',\n",
       "  'first_name': u'Francis',\n",
       "  'gid': 1015,\n",
       "  'last_name': u'Parkman',\n",
       "  'title': u'The Oregon Trail: Sketches of Prairie and Rocky-Mountain Life'},\n",
       " {'birth_year': u'1632',\n",
       "  'death_year': u'1677',\n",
       "  'first_name': u'Benedictus de',\n",
       "  'gid': 1016,\n",
       "  'last_name': u'Spinoza',\n",
       "  'title': u'On the Improvement of the Understanding'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rdd.keys().take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many do we have left? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of books after filtering:  10976\n"
     ]
    }
   ],
   "source": [
    "print 'number of books after filtering: ', filtered_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the books end up in multiple files, but they should all have the same gid. \n",
    "\n",
    "To check for this we will use one of the most basic and common Map/Reduce patterns: \n",
    "\n",
    "* map the data into `key`,`value` pairs where `key` is the quantity we want to count and `value` is just 1. \n",
    "* invoke a reduction *by key*, where the reduction operator is a simple addition\n",
    "\n",
    "Finally, we will sort the result and print out the first few elements to check whether we have to worry about documents spanning multiple files or not. \n",
    "\n",
    "The RDD operations that are needed are [`reduceByKey`](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey) and [sortBy](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.sortBy).\n",
    "\n",
    "For the `keyFunc` of the call to `sortBy`, use a `lambda` function that extracts the counts obtained from the `reduceByKey`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6478, 43),\n",
       " (3772, 40),\n",
       " (8700, 35),\n",
       " (3332, 33),\n",
       " (12233, 29),\n",
       " (3425, 23),\n",
       " (2440, 16),\n",
       " (6475, 15),\n",
       " (12145, 9),\n",
       " (12383, 7),\n",
       " (15000, 6),\n",
       " (10625, 5),\n",
       " (12030, 5),\n",
       " (4022, 5),\n",
       " (16927, 4),\n",
       " (10800, 4),\n",
       " (14052, 3),\n",
       " (14860, 3),\n",
       " (14495, 2),\n",
       " (1079, 2)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(filtered_rdd.map(lambda (meta, text): (meta['gid'], 1))\n",
    "             .reduceByKey(add)\n",
    "             .sortBy(lambda (key,count): count, False)\n",
    "             .take(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a few that are made up of multiple sections. To combine them, we will use `reduceByKey` which will result in having an RDD of `gid`'s as keys and the combined text of each `gid`. The reduction function in `reduceByKey` can be a simple in-line function that just adds two elements together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_rdd = (filtered_rdd.map(lambda (meta, text): (meta['gid'], text))\n",
    "                           .reduceByKey(lambda a,b: a+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple sanity check, lets look at `gid`=6478, which according to the cell above has 43 sections in the original dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_rdd.map(lambda (meta, text): (meta['gid'],1)).lookup(6478))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_rdd.lookup(6478))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid having to do all these pre-processing steps again at a later point, lets also save the `cleaned_rdd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_rdd.saveAsPickleFile('/user/roskarr/gutenberg/cleaned_rdd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now saved in the directory we specified, one file per partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -XX:ParallelGCThreads=1\n",
      "15/06/19 11:46:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 201 items\n",
      "-rw-r--r--   3 roskarr supergroup          0 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/_SUCCESS\n",
      "-rw-r--r--   3 roskarr supergroup   90662087 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00000\n",
      "-rw-r--r--   3 roskarr supergroup   25827115 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00001\n",
      "-rw-r--r--   3 roskarr supergroup   18721125 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00002\n",
      "-rw-r--r--   3 roskarr supergroup   22067951 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00003\n",
      "-rw-r--r--   3 roskarr supergroup   19626700 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00004\n",
      "-rw-r--r--   3 roskarr supergroup   21188890 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00005\n",
      "-rw-r--r--   3 roskarr supergroup   22330584 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00006\n",
      "-rw-r--r--   3 roskarr supergroup   22251456 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00007\n",
      "-rw-r--r--   3 roskarr supergroup   16715880 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00008\n",
      "-rw-r--r--   3 roskarr supergroup   19982363 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00009\n",
      "-rw-r--r--   3 roskarr supergroup   21065196 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00010\n",
      "-rw-r--r--   3 roskarr supergroup   21219505 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00011\n",
      "-rw-r--r--   3 roskarr supergroup   19131870 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00012\n",
      "-rw-r--r--   3 roskarr supergroup   21348137 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00013\n",
      "-rw-r--r--   3 roskarr supergroup   22942347 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00014\n",
      "-rw-r--r--   3 roskarr supergroup   24520429 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00015\n",
      "-rw-r--r--   3 roskarr supergroup   17822700 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00016\n",
      "-rw-r--r--   3 roskarr supergroup   19238417 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00017\n",
      "-rw-r--r--   3 roskarr supergroup   19329301 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00018\n",
      "-rw-r--r--   3 roskarr supergroup   17514311 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00019\n",
      "-rw-r--r--   3 roskarr supergroup   16366258 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00020\n",
      "-rw-r--r--   3 roskarr supergroup   15484062 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00021\n",
      "-rw-r--r--   3 roskarr supergroup   17754293 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00022\n",
      "-rw-r--r--   3 roskarr supergroup   19420668 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00023\n",
      "-rw-r--r--   3 roskarr supergroup   18996854 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00024\n",
      "-rw-r--r--   3 roskarr supergroup   18664756 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00025\n",
      "-rw-r--r--   3 roskarr supergroup   20444340 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00026\n",
      "-rw-r--r--   3 roskarr supergroup   20253899 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00027\n",
      "-rw-r--r--   3 roskarr supergroup   15414854 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00028\n",
      "-rw-r--r--   3 roskarr supergroup   19827191 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00029\n",
      "-rw-r--r--   3 roskarr supergroup   17369916 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00030\n",
      "-rw-r--r--   3 roskarr supergroup   20306460 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00031\n",
      "-rw-r--r--   3 roskarr supergroup   19036039 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00032\n",
      "-rw-r--r--   3 roskarr supergroup   21200833 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00033\n",
      "-rw-r--r--   3 roskarr supergroup   19954151 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00034\n",
      "-rw-r--r--   3 roskarr supergroup   17238166 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00035\n",
      "-rw-r--r--   3 roskarr supergroup   20121083 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00036\n",
      "-rw-r--r--   3 roskarr supergroup   16159477 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00037\n",
      "-rw-r--r--   3 roskarr supergroup   13445802 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00038\n",
      "-rw-r--r--   3 roskarr supergroup   19718962 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00039\n",
      "-rw-r--r--   3 roskarr supergroup   17270108 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00040\n",
      "-rw-r--r--   3 roskarr supergroup   16861155 2015-06-18 18:35 /user/roskarr/gutenberg/cleaned_rdd/part-00041\n",
      "-rw-r--r--   3 roskarr supergroup   15936987 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00042\n",
      "-rw-r--r--   3 roskarr supergroup   20481855 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00043\n",
      "-rw-r--r--   3 roskarr supergroup   18303062 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00044\n",
      "-rw-r--r--   3 roskarr supergroup   18451159 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00045\n",
      "-rw-r--r--   3 roskarr supergroup   21379663 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00046\n",
      "-rw-r--r--   3 roskarr supergroup   23933828 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00047\n",
      "-rw-r--r--   3 roskarr supergroup   20646036 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00048\n",
      "-rw-r--r--   3 roskarr supergroup   31712069 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00049\n",
      "-rw-r--r--   3 roskarr supergroup   16353942 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00050\n",
      "-rw-r--r--   3 roskarr supergroup   23485543 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00051\n",
      "-rw-r--r--   3 roskarr supergroup   28127669 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00052\n",
      "-rw-r--r--   3 roskarr supergroup   21859213 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00053\n",
      "-rw-r--r--   3 roskarr supergroup   27421753 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00054\n",
      "-rw-r--r--   3 roskarr supergroup   17743823 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00055\n",
      "-rw-r--r--   3 roskarr supergroup   14964817 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00056\n",
      "-rw-r--r--   3 roskarr supergroup   19916305 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00057\n",
      "-rw-r--r--   3 roskarr supergroup   19876905 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00058\n",
      "-rw-r--r--   3 roskarr supergroup   16258519 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00059\n",
      "-rw-r--r--   3 roskarr supergroup   26137088 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00060\n",
      "-rw-r--r--   3 roskarr supergroup   21813583 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00061\n",
      "-rw-r--r--   3 roskarr supergroup   18458146 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00062\n",
      "-rw-r--r--   3 roskarr supergroup   20259000 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00063\n",
      "-rw-r--r--   3 roskarr supergroup   19841142 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00064\n",
      "-rw-r--r--   3 roskarr supergroup   18747836 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00065\n",
      "-rw-r--r--   3 roskarr supergroup   18327728 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00066\n",
      "-rw-r--r--   3 roskarr supergroup   24622371 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00067\n",
      "-rw-r--r--   3 roskarr supergroup   23783006 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00068\n",
      "-rw-r--r--   3 roskarr supergroup   25086800 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00069\n",
      "-rw-r--r--   3 roskarr supergroup   21604836 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00070\n",
      "-rw-r--r--   3 roskarr supergroup   21644755 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00071\n",
      "-rw-r--r--   3 roskarr supergroup   23435404 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00072\n",
      "-rw-r--r--   3 roskarr supergroup   18782005 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00073\n",
      "-rw-r--r--   3 roskarr supergroup   24329077 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00074\n",
      "-rw-r--r--   3 roskarr supergroup   19300848 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00075\n",
      "-rw-r--r--   3 roskarr supergroup   24856623 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00076\n",
      "-rw-r--r--   3 roskarr supergroup   18932413 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00077\n",
      "-rw-r--r--   3 roskarr supergroup   20902772 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00078\n",
      "-rw-r--r--   3 roskarr supergroup   18888832 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00079\n",
      "-rw-r--r--   3 roskarr supergroup   21840426 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00080\n",
      "-rw-r--r--   3 roskarr supergroup   21215984 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00081\n",
      "-rw-r--r--   3 roskarr supergroup   20921917 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00082\n",
      "-rw-r--r--   3 roskarr supergroup   19865246 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00083\n",
      "-rw-r--r--   3 roskarr supergroup   23526279 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00084\n",
      "-rw-r--r--   3 roskarr supergroup   23868074 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00085\n",
      "-rw-r--r--   3 roskarr supergroup   19066315 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00086\n",
      "-rw-r--r--   3 roskarr supergroup   17512613 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00087\n",
      "-rw-r--r--   3 roskarr supergroup   18001594 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00088\n",
      "-rw-r--r--   3 roskarr supergroup   17136950 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00089\n",
      "-rw-r--r--   3 roskarr supergroup   21322648 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00090\n",
      "-rw-r--r--   3 roskarr supergroup   19006373 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00091\n",
      "-rw-r--r--   3 roskarr supergroup   17562211 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00092\n",
      "-rw-r--r--   3 roskarr supergroup   20506650 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00093\n",
      "-rw-r--r--   3 roskarr supergroup   17087509 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00094\n",
      "-rw-r--r--   3 roskarr supergroup   20829447 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00095\n",
      "-rw-r--r--   3 roskarr supergroup   20487992 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00096\n",
      "-rw-r--r--   3 roskarr supergroup   16769869 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00097\n",
      "-rw-r--r--   3 roskarr supergroup   18881953 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00098\n",
      "-rw-r--r--   3 roskarr supergroup   19486063 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00099\n",
      "-rw-r--r--   3 roskarr supergroup   52184605 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00100\n",
      "-rw-r--r--   3 roskarr supergroup   23485075 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00101\n",
      "-rw-r--r--   3 roskarr supergroup   19218590 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00102\n",
      "-rw-r--r--   3 roskarr supergroup   17849468 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00103\n",
      "-rw-r--r--   3 roskarr supergroup   19132150 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00104\n",
      "-rw-r--r--   3 roskarr supergroup   18980030 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00105\n",
      "-rw-r--r--   3 roskarr supergroup   22989512 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00106\n",
      "-rw-r--r--   3 roskarr supergroup   19010759 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00107\n",
      "-rw-r--r--   3 roskarr supergroup   20038882 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00108\n",
      "-rw-r--r--   3 roskarr supergroup   17362287 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00109\n",
      "-rw-r--r--   3 roskarr supergroup   18179417 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00110\n",
      "-rw-r--r--   3 roskarr supergroup   17182618 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00111\n",
      "-rw-r--r--   3 roskarr supergroup   15223467 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00112\n",
      "-rw-r--r--   3 roskarr supergroup   15630772 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00113\n",
      "-rw-r--r--   3 roskarr supergroup   19861087 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00114\n",
      "-rw-r--r--   3 roskarr supergroup   18472340 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00115\n",
      "-rw-r--r--   3 roskarr supergroup   18526156 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00116\n",
      "-rw-r--r--   3 roskarr supergroup   18833073 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00117\n",
      "-rw-r--r--   3 roskarr supergroup   17042013 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00118\n",
      "-rw-r--r--   3 roskarr supergroup   16262452 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00119\n",
      "-rw-r--r--   3 roskarr supergroup   21427257 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00120\n",
      "-rw-r--r--   3 roskarr supergroup   22299164 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00121\n",
      "-rw-r--r--   3 roskarr supergroup   19305374 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00122\n",
      "-rw-r--r--   3 roskarr supergroup   18058104 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00123\n",
      "-rw-r--r--   3 roskarr supergroup   13806683 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00124\n",
      "-rw-r--r--   3 roskarr supergroup   22234762 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00125\n",
      "-rw-r--r--   3 roskarr supergroup   17595655 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00126\n",
      "-rw-r--r--   3 roskarr supergroup   21278517 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00127\n",
      "-rw-r--r--   3 roskarr supergroup   20215360 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00128\n",
      "-rw-r--r--   3 roskarr supergroup   20209446 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00129\n",
      "-rw-r--r--   3 roskarr supergroup   19849872 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00130\n",
      "-rw-r--r--   3 roskarr supergroup   20073806 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00131\n",
      "-rw-r--r--   3 roskarr supergroup   23274874 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00132\n",
      "-rw-r--r--   3 roskarr supergroup   17710468 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00133\n",
      "-rw-r--r--   3 roskarr supergroup   21060756 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00134\n",
      "-rw-r--r--   3 roskarr supergroup   23259064 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00135\n",
      "-rw-r--r--   3 roskarr supergroup   18520857 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00136\n",
      "-rw-r--r--   3 roskarr supergroup   20876970 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00137\n",
      "-rw-r--r--   3 roskarr supergroup   14449188 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00138\n",
      "-rw-r--r--   3 roskarr supergroup   14536416 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00139\n",
      "-rw-r--r--   3 roskarr supergroup   20914935 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00140\n",
      "-rw-r--r--   3 roskarr supergroup   18212277 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00141\n",
      "-rw-r--r--   3 roskarr supergroup   16518639 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00142\n",
      "-rw-r--r--   3 roskarr supergroup   16529472 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00143\n",
      "-rw-r--r--   3 roskarr supergroup   15175493 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00144\n",
      "-rw-r--r--   3 roskarr supergroup   26788610 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00145\n",
      "-rw-r--r--   3 roskarr supergroup   23578408 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00146\n",
      "-rw-r--r--   3 roskarr supergroup   17339523 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00147\n",
      "-rw-r--r--   3 roskarr supergroup   17181039 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00148\n",
      "-rw-r--r--   3 roskarr supergroup   25007554 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00149\n",
      "-rw-r--r--   3 roskarr supergroup   21827413 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00150\n",
      "-rw-r--r--   3 roskarr supergroup   18556548 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00151\n",
      "-rw-r--r--   3 roskarr supergroup   18283737 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00152\n",
      "-rw-r--r--   3 roskarr supergroup   18981197 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00153\n",
      "-rw-r--r--   3 roskarr supergroup   19104672 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00154\n",
      "-rw-r--r--   3 roskarr supergroup   20913780 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00155\n",
      "-rw-r--r--   3 roskarr supergroup   20727359 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00156\n",
      "-rw-r--r--   3 roskarr supergroup   16982151 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00157\n",
      "-rw-r--r--   3 roskarr supergroup   17119601 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00158\n",
      "-rw-r--r--   3 roskarr supergroup   18865593 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00159\n",
      "-rw-r--r--   3 roskarr supergroup   20698303 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00160\n",
      "-rw-r--r--   3 roskarr supergroup   20653337 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00161\n",
      "-rw-r--r--   3 roskarr supergroup   20456397 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00162\n",
      "-rw-r--r--   3 roskarr supergroup   20216194 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00163\n",
      "-rw-r--r--   3 roskarr supergroup   21389292 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00164\n",
      "-rw-r--r--   3 roskarr supergroup   21731564 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00165\n",
      "-rw-r--r--   3 roskarr supergroup   22928717 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00166\n",
      "-rw-r--r--   3 roskarr supergroup   23585989 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00167\n",
      "-rw-r--r--   3 roskarr supergroup   20840957 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00168\n",
      "-rw-r--r--   3 roskarr supergroup   18885045 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00169\n",
      "-rw-r--r--   3 roskarr supergroup   26456975 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00170\n",
      "-rw-r--r--   3 roskarr supergroup   20408957 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00171\n",
      "-rw-r--r--   3 roskarr supergroup   18017116 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00172\n",
      "-rw-r--r--   3 roskarr supergroup   19692749 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00173\n",
      "-rw-r--r--   3 roskarr supergroup   21559176 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00174\n",
      "-rw-r--r--   3 roskarr supergroup   16995327 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00175\n",
      "-rw-r--r--   3 roskarr supergroup   20546518 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00176\n",
      "-rw-r--r--   3 roskarr supergroup   18776397 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00177\n",
      "-rw-r--r--   3 roskarr supergroup   16677617 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00178\n",
      "-rw-r--r--   3 roskarr supergroup   19347271 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00179\n",
      "-rw-r--r--   3 roskarr supergroup   24536534 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00180\n",
      "-rw-r--r--   3 roskarr supergroup   27546576 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00181\n",
      "-rw-r--r--   3 roskarr supergroup   18395784 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00182\n",
      "-rw-r--r--   3 roskarr supergroup   18913609 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00183\n",
      "-rw-r--r--   3 roskarr supergroup   24080505 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00184\n",
      "-rw-r--r--   3 roskarr supergroup   16315340 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00185\n",
      "-rw-r--r--   3 roskarr supergroup   15239921 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00186\n",
      "-rw-r--r--   3 roskarr supergroup   21929151 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00187\n",
      "-rw-r--r--   3 roskarr supergroup   14923596 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00188\n",
      "-rw-r--r--   3 roskarr supergroup   17694052 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00189\n",
      "-rw-r--r--   3 roskarr supergroup   12916943 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00190\n",
      "-rw-r--r--   3 roskarr supergroup   16893994 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00191\n",
      "-rw-r--r--   3 roskarr supergroup   14610300 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00192\n",
      "-rw-r--r--   3 roskarr supergroup   17128107 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00193\n",
      "-rw-r--r--   3 roskarr supergroup   20560430 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00194\n",
      "-rw-r--r--   3 roskarr supergroup   16992331 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00195\n",
      "-rw-r--r--   3 roskarr supergroup   21756140 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00196\n",
      "-rw-r--r--   3 roskarr supergroup   25968318 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00197\n",
      "-rw-r--r--   3 roskarr supergroup   19167653 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00198\n",
      "-rw-r--r--   3 roskarr supergroup   19103224 2015-06-18 18:36 /user/roskarr/gutenberg/cleaned_rdd/part-00199\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/roskarr/gutenberg/cleaned_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data\n",
    "\n",
    "We're finished with the basic pre-processing. Our `cleaned_rdd` contains `gid`'s as keys and text as values. If we want some other piece of metadata, we can just call the `get_metadata` function inside a `map` to extract it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of book years\n",
    "Now we're ready to start asking some questions of the data. To begin with, lets do a simple histogram of the year distribution of the books. Since we don't have original publication dates, we just use the simple formula: \n",
    "\n",
    "$year = max\\left((year_{birth} + year_{death})/2, year_{birth} + offset\\right)$, \n",
    "\n",
    "where $offset$ is a number drawn from a gaussian centered on 40 with a $\\sigma$ of 5 years. This means that we assume most people write their books around 40. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def publication_year(meta) : \n",
    "    import numpy as np\n",
    "    birth_year = int(meta['birth_year'])\n",
    "    if meta['death_year'] is None : \n",
    "        year = birth_year + np.random.normal(40,5)\n",
    "    else :\n",
    "        death_year = int(meta['death_year'])\n",
    "        year = max((birth_year + death_year) / 2.0, birth_year+np.random.normal(40,5))\n",
    "\n",
    "    return min(year,2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_rdd = cleaned_rdd.map(lambda (gid, text): publication_year(get_metadata(gid))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_rdd.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram function actually already exists in the Spark API (but it didn't use to!). However, for fun we will write our own. Calculating the histogram can be split up into two parts. First, we need to figure out which bin each value corresponds to: \n",
    "\n",
    "1. take bins and a value as input\n",
    "2. calculate the bin that the value maps to and return (`bin`, 1) pair\n",
    "\n",
    "Second, we need to do a simple `reduceByKey` where we just add up all the values belonging to each bin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bisect import bisect_right\n",
    "import numpy as np\n",
    "def get_bin(bin_edges, value) : \n",
    "    return bisect_right(bin_edges, value) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram(rdd, nbins = 100, min_val=None, max_val=None) :\n",
    "    # if either min_val or max_val are missing, get them from the data\n",
    "    if min_val is None : \n",
    "        min_val = rdd.min()\n",
    "    if max_val is None : \n",
    "        max_val = rdd.max()\n",
    "        \n",
    "    bin_edges = np.linspace(min_val,max_val,nbins+1)\n",
    "    \n",
    "    binned_rdd = rdd.map(lambda x: (get_bin(bin_edges, x),1))\n",
    "    \n",
    "    res = binned_rdd.reduceByKey(lambda a,b:a+b).collect()\n",
    "    \n",
    "    # This is a sparse result -- turn into a dense vector for plotting: \n",
    "    res_full = np.zeros(nbins)\n",
    "    overflow = 0\n",
    "    for item in res : \n",
    "        if item[0] > len(res_full)-1 or item[0] < 0: \n",
    "            continue #overflow += item[1]\n",
    "        else: res_full[item[0]] = item[1]\n",
    "  #  res_full[-1] += overflow\n",
    "    \n",
    "    return .5*(bin_edges[:-1]+bin_edges[1:]), res_full, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 105 ms, sys: 25 ms, total: 130 ms\n",
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "res = histogram(cleaned_rdd.map(lambda (gid,text): int(meta_b.value[gid]['birth_year'])), min_val=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b36b8ba4ad0>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA8HMzAAHgpmZZQ4EMzMD4P8DT8vdENtGKLIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b36b86c5210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res[0], res[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a corpus-wide vocabulary\n",
    "We could have done the above histogram without ever invoking a distributed processing framework of course by simply extracting the years from the metadata. The text body of each data element is where the bulk of the data volume lies. \n",
    "\n",
    "To construct a corpus wide vocabulary, we have to deconstruct each document into a list of words and then extract the unique words from the entire data set. If our dataset fit into memory of a single machine, this is a simple set operation. But what if it doesn't? \n",
    "\n",
    "We'll assume this is the case and instead of converting each `gid,text` pair into a `gid,list_of_words` pair, we will simply construct one RDD of words. Here we aren't necessarily interested in preserving the provenance of words, but just finding the unique words in the whole corpus. \n",
    "\n",
    "1. map the entire RDD of text into an RDD of single words\n",
    "2. use the `distinct` method of the resulting RDD to transform it into an RDD with only unique words\n",
    "\n",
    "*Hint:* In python, splitting a string into a set of words separated by spaces is easy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['splitting', 'a', 'string', 'is', 'super', 'simple']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'splitting a string is super simple'\n",
    "line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_rdd = cleaned_rdd.flatMap(lambda (gid, text): text.split()).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  2805048\n"
     ]
    }
   ],
   "source": [
    "print \"Number of unique words: \", distinct_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"MapReduce\" tutorial would self destruct if it didn't include a word counting example. So, lets count the occurences of all the words across the entire corpus. This is a fairly straightforward operation: \n",
    "\n",
    "1. `map` each word into a (`word, count`) pair\n",
    "2. call `reduceByKey` to sum up all the `count`s for each word\n",
    "3. finally to make it useful, sort it in descending order\n",
    "\n",
    "*hint:* think about which mapping method you need to use to convert the single item (`text`) into many items (individual words)\n",
    "\n",
    "*hint \\#2:* list comprehension can lead to a nice concise solution here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = (cleaned_rdd.flatMap(lambda (gid, text): [(word,1) for word in text.split()])\n",
    "                         .reduceByKey(lambda a,b: a+b)\n",
    "                         .sortBy(lambda (word, count): count, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 47035036),\n",
       " ('of', 25973952),\n",
       " ('and', 24212041),\n",
       " ('to', 20546246),\n",
       " ('a', 15731834),\n",
       " ('in', 13394565),\n",
       " ('that', 9063159),\n",
       " ('i', 8370910),\n",
       " ('he', 8367365),\n",
       " ('was', 8131835),\n",
       " ('it', 7657038),\n",
       " ('his', 6919891),\n",
       " ('with', 6272850),\n",
       " ('for', 5850743),\n",
       " ('as', 5774070),\n",
       " ('is', 5769890),\n",
       " ('you', 5413220),\n",
       " ('had', 5075729),\n",
       " ('not', 4668707),\n",
       " ('her', 4372450),\n",
       " ('at', 4368744),\n",
       " ('be', 4363714),\n",
       " ('but', 4358541),\n",
       " ('on', 4172546),\n",
       " ('by', 3914924),\n",
       " ('this', 3744877),\n",
       " ('which', 3597949),\n",
       " ('she', 3554704),\n",
       " ('have', 3436484),\n",
       " ('from', 3281687),\n",
       " ('or', 3192292),\n",
       " ('him', 3102583),\n",
       " ('they', 3084159),\n",
       " ('all', 3069227),\n",
       " ('my', 2733775),\n",
       " ('were', 2673387),\n",
       " ('are', 2478379),\n",
       " ('so', 2449712),\n",
       " ('we', 2443400),\n",
       " ('one', 2348789),\n",
       " ('me', 2296231),\n",
       " ('an', 2257107),\n",
       " ('their', 2219106),\n",
       " ('no', 2122726),\n",
       " ('if', 2117104),\n",
       " ('there', 2063181),\n",
       " ('would', 1969250),\n",
       " ('who', 1964489),\n",
       " ('when', 1900255),\n",
       " ('been', 1882207)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets exclude the most trivial words (stop words). A `set` object with the most common stop words is saved in the same directory as this notebook so we can simply load it with `pickle`. Then we use it to modify the list comprehension with an `if` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "ENGLISH_STOP_WORDS = load(open('stop_words.dump'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = (cleaned_rdd.flatMap(lambda (gid, text): [(word,1) for word in text.split() if word not in ENGLISH_STOP_WORDS])\n",
    "                         .reduceByKey(lambda a,b: a+b)\n",
    "                         .sortBy(lambda (word, count): count, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduces, Shuffles, and Partitioning\n",
    "During a `reduceByKey`, or any other reduction for that matter, data must be shuffled around the cluster and combined. By default, this is done in an intelligent way by first reducing values locally on each partition, and then combining the results of the partitions. Still, as is the case here, for common keys, every partition will have to send its results to others. This can result in a lot of temporary file IO if the data that needs to be communicated can't all be held in memory on all of the executors. \n",
    "\n",
    "One way around this is to partition the data ahead of time so that the same keys land on the same partition by design. This results in much less data needing to be shipped around the network and can improve the performance. Of course, at the cost of an expensive initial shuffle! But if many reductions have to be done on the same data, it might be worth it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_rdd = cleaned_rdd.flatMap(lambda (gid, text): [(word,1) for word in text.split() if word not in ENGLISH_STOP_WORDS]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323043149"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we re-partition the `word_rdd` using the built-in hashing function, which just turns the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_partitions = word_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323043149"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = word_rdd.partitionBy(num_partitions, lambda x: hash(x)%num_partitions).cache()\n",
    "par.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both datasets are cached in memory, we can compare the time it takes the reduce step to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85 ms, sys: 17 ms, total: 102 ms\n",
      "Wall time: 14.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2804732"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word_rdd.reduceByKey(lambda a,b: a+b).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74 ms, sys: 16 ms, total: 90 ms\n",
      "Wall time: 8.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2804732"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "par.reduceByKey(lambda a,b: a+b).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A ~ 40% improvement! Not bad, though we can expect the difference to depend on the nature of the dataset. If you inspect the Spark UI, you can see that the first `reduceByKey` (i.e. one done on `word_rdd`) shuffled ~390 Mb of data, while the second `reduceByKey` (i.e. done on `par`) only shuffled ~50 Mb of data. This dataset is still pretty small, but when the shuffles are in the Gb range, the differences can be substantial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

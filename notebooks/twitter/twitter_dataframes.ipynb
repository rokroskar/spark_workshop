{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import sys, os, glob\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import findspark, os\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# put the number of executors and cores into variables so we can refer to it later\n",
    "num_execs = 200\n",
    "exec_cores = 4\n",
    "\n",
    "# initializing the SparkConf\n",
    "os.environ['SPARK_DRIVER_MEMORY'] = '4g'\n",
    "os.environ['SPARK_CONF_DIR'] = '%s/spark_config'%os.getcwd()\n",
    "conf = (SparkConf()\n",
    "            .set('spark.executor.memory', '8g')\n",
    "            .set('spark.executor.instances', str(num_execs))\n",
    "            .set('spark.executor.cores', str(exec_cores))\n",
    "            .set('spark.storage.memoryFraction', 0.6)\n",
    "            .set('spark.shuffle.memoryFraction', 0.2)\n",
    "            .set('spark.yarn.executor.memoryOverhead', 2048)\n",
    "            .set('spark.executor.extraJavaOptions', '-XX:+UseCompressedOops')\n",
    "            .set('spark.yarn.am.memory', '8g')\n",
    "            .set('spark.yarn.am.cores', 12)\n",
    "            .set('spark.driver.maxResultSize', '4096')\n",
    "            .set('spark.akka.frameSize', 256)\n",
    "            .set('spark.akka.threads', 6)\n",
    "            .set('spark.executorEnv.PYTHONPATH', \n",
    "                 '/cluster/apps/spark/spark-current/python:/cluster/apps/spark/spark-current/python/lib/py4j-0.8.2.1-src.zip')\n",
    "            .set('spark.executorEnv.PATH', os.environ['PATH']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(master = 'yarn-client', conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = sqc.read.parquet('/user/roskarr/twitter/2014_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqc.registerDataFrameAsTable(data2, 'tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.groupBy(data2.retweet_count).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.groupBy(data2.retweeted).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filt = data2.where(data2.retweeted == 'True')\n",
    "data_filt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.take(5)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snakebite import client\n",
    "\n",
    "cl = client.Client('hadoop.ethz.ch', 8020)\n",
    "\n",
    "import re\n",
    "\n",
    "for d in filter(lambda x: x['file_type'] == 'd', cl.ls(['/user/imoise/TwitterData'])) :\n",
    "    year_month = re.findall('/(\\w+_\\w+)',d['path'])\n",
    "    if len(year_month) > 0 : \n",
    "        year_month = year_month[0]\n",
    "        (sqc.read.json('%s/*/*'%d['path'])\n",
    "                 .coalesce(500)\n",
    "                 .write.mode('overwrite')\n",
    "                 .parquet('/user/roskarr/twitter/%s'%year_month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

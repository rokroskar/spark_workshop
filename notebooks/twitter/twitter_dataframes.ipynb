{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import sys, os, glob\n",
    "import numpy as np\n",
    "\n",
    "# set some nicer plotting options\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqc = SQLContext(sc)\n",
    "hc = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Xmx10G -Xms256m -XX:ParallelGCThreads=5\n",
      "15/11/11 16:56:16 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 7 items\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:21 /user/roskarr/twitter/2014_05\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:26 /user/roskarr/twitter/2014_06\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:31 /user/roskarr/twitter/2014_07\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:37 /user/roskarr/twitter/2014_09\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:43 /user/roskarr/twitter/2014_10\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:49 /user/roskarr/twitter/2014_11\n",
      "drwxr-xr-x   - roskarr supergroup          0 2015-11-02 16:50 /user/roskarr/twitter/2014_12\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/roskarr/twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Xmx10G -Xms256m -XX:ParallelGCThreads=5\n",
      "15/11/11 16:56:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "55.1 G  /user/roskarr/twitter/2014_05\n",
      "31.7 G  /user/roskarr/twitter/2014_06\n",
      "51.0 G  /user/roskarr/twitter/2014_07\n",
      "59.6 G  /user/roskarr/twitter/2014_09\n",
      "61.9 G  /user/roskarr/twitter/2014_10\n",
      "62.0 G  /user/roskarr/twitter/2014_11\n",
      "12.1 G  /user/roskarr/twitter/2014_12\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -du -h /user/roskarr/twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 ms, sys: 6 ms, total: 19 ms\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = hc.read.parquet('/user/roskarr/twitter/2014_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import IntegerType, ArrayType, StringType, StructField, StructType, DateType, DataType, DateConverter, DatetimeConverter, TimestampType, BooleanType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convert_date_string = func.udf(lambda date_string: datetime.date.strftime(datetime.datetime.strptime(date_string, '%a %b %d %H:%M:%S +0000 %Y'),'%Y-%m-%d %H:%M:%S'), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make UDF for converting the date string to a datetime object\n",
    "datetime_udf = func.udf(lambda date_string: datetime.strptime(date_string, '%a %b %d %H:%M:%S +0000 %Y'), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hash_text_udf = func.udf(lambda row: [r.text for r in row], returnType=ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, hashtag: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the tweets with at least one hashtag\n",
    "hashtag_df = (data.select('created_at', 'entities.hashtags')\n",
    "                .filter(func.size('hashtags') > 0)\n",
    "                .withColumn('hash_text', hash_text_udf('hashtags'))\n",
    "                .select(convert_date_string('created_at').alias('date'), func.explode('hash_text').alias('hashtag'))\n",
    "                .withColumn('hashtag', func.lower(func.col('hashtag')))\n",
    "                .repartition(1200))\n",
    "hashtag_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------------+\n",
      "|date               |hashtag                    |\n",
      "+-------------------+---------------------------+\n",
      "|2014-10-01 06:37:50|芸能                         |\n",
      "|2014-10-01 18:53:15|miracles                   |\n",
      "|2014-10-02 00:37:25|horortamanlangsatmayestik  |\n",
      "|2014-10-02 12:23:46|photography                |\n",
      "|2014-10-02 17:12:49|falltourfollow             |\n",
      "|2014-10-02 19:49:59|zi̇raatmühendi̇si̇6500kadro|\n",
      "|2014-10-03 19:00:54|mgwv                       |\n",
      "|2014-10-04 05:50:08|gta                        |\n",
      "|2014-10-04 22:11:40|hadith                     |\n",
      "|2014-10-05 06:01:07|حقيقه                      |\n",
      "|2014-10-05 13:00:21|rtagree                    |\n",
      "|2014-10-05 16:49:22|nsfw                       |\n",
      "|2014-10-06 17:54:31|iphone                     |\n",
      "|2014-10-06 23:14:57|vikingstrong               |\n",
      "|2014-10-07 17:17:07|99inyql                    |\n",
      "|2014-10-07 21:23:19|amantesdecádiz             |\n",
      "|2014-10-08 12:16:02|ipadgames                  |\n",
      "|2014-10-08 23:30:15|verified                   |\n",
      "|2014-10-09 01:26:34|المغرب                     |\n",
      "|2014-10-09 17:27:39|jamesandjames              |\n",
      "+-------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashtag_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple word count revisited\n",
    "\n",
    "Now that we have a `DataFrame` consisting of `(timestamp, hashtag)` columns, lets do a simple word count using the `DataFrame` API. This will let us decide later on which hashtags we might be interested in investigating further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-------+\n",
      "|hashtag                   |count  |\n",
      "+--------------------------+-------+\n",
      "|emabiggestfans1d          |1006026|\n",
      "|emabiggestfansjustinbieber|973621 |\n",
      "|kcaargentina              |746633 |\n",
      "|gameinsight               |409308 |\n",
      "|android                   |300233 |\n",
      "|تطبيق_قرآنى               |282558 |\n",
      "|androidgames              |217769 |\n",
      "|teamfollowback            |186653 |\n",
      "|rt                        |184199 |\n",
      "|كنز_المسلم                |173564 |\n",
      "|رتويت                     |162817 |\n",
      "|ipad                      |157261 |\n",
      "|الهلال                    |154979 |\n",
      "|sougofollow               |154090 |\n",
      "|相互フォロー                    |143476 |\n",
      "|rtした人全員フォローする             |140583 |\n",
      "|ipadgames                 |138735 |\n",
      "|follow                    |124292 |\n",
      "|porn                      |123463 |\n",
      "|الرياض                    |120912 |\n",
      "|ff                        |118390 |\n",
      "|السعودية                  |116091 |\n",
      "|followback                |111813 |\n",
      "|gonzalohiguain            |109991 |\n",
      "|laliesposito              |109843 |\n",
      "|mgwv                      |108273 |\n",
      "|followtrick               |104756 |\n",
      "|openfollow                |104729 |\n",
      "|retweet                   |100114 |\n",
      "|love                      |98081  |\n",
      "|iphone                    |91404  |\n",
      "|النصر                     |88614  |\n",
      "|news                      |86642  |\n",
      "|nowplaying                |86267  |\n",
      "|tfb                       |86065  |\n",
      "|sex                       |83634  |\n",
      "|babyonemoretime           |78051  |\n",
      "|tfbjp                     |77225  |\n",
      "|job                       |76417  |\n",
      "|free                      |69751  |\n",
      "|سكس                       |69524  |\n",
      "|拡散希望                      |66190  |\n",
      "|orianasabatini            |62697  |\n",
      "|followme                  |60260  |\n",
      "|julianserrano             |59467  |\n",
      "|amas                      |58345  |\n",
      "|emabiggestfansarianagrande|56493  |\n",
      "|ريتويت                    |56489  |\n",
      "|wannabe                   |55319  |\n",
      "|mercedeslambre            |52299  |\n",
      "+--------------------------+-------+\n",
      "only showing top 50 rows\n",
      "\n",
      "CPU times: user 181 ms, sys: 49 ms, total: 230 ms\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "hashtag_df.groupBy('hashtag').count().sort('count', ascending=False).show(50, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, there are lots os languages represented on Twitter! This is very interesting by itself, but for now lets focus on just plain ascii hash tags which we are more likely to understand: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a helper UDF that can be used to filter non-ascii hashtags\n",
    "def is_ascii(s):\n",
    "    return all(ord(c) > 0 and ord(c) < 128 for c in s)\n",
    "is_ascii_udf = func.udf(is_ascii, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashtag_df = hashtag_df.filter(is_ascii_udf('hashtag'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily hashtag trends\n",
    "\n",
    "Now lets do something slightly more complicated and incorporate the time data into our analysis. First, we'll try daily trends and later on do more fine-grained analysis. \n",
    "\n",
    "To get information about daily hashtag usage, we must first convert the date string into a number representing day of the year. The [Spark DataFrame functions module](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions) provides a function [dayofyear](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.dayofyear) that will do this for us and we can use it just like we used the User Defined Functions (UDFs) above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+--------------------+\n",
      "|month|week|day|             hashtag|\n",
      "+-----+----+---+--------------------+\n",
      "|   10|  40|274|            miracles|\n",
      "|   10|  40|275|horortamanlangsat...|\n",
      "|   10|  40|275|         photography|\n",
      "|   10|  40|275|      falltourfollow|\n",
      "|   10|  40|276|                mgwv|\n",
      "+-----+----+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_hashtag = hashtag_df.select(func.month('date').alias('month'),\n",
    "                                  func.weekofyear('date').alias('week'),\n",
    "                                  func.dayofyear('date').alias('day'), \n",
    "                                  'hashtag')\n",
    "daily_hashtag.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the same technique as above using `groupBy` to get daily counts for each hashtag. Since we want to satisfy two conditions (counts per day and counts per hashtag), we simply give `groupBy` two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day_counts = (daily_hashtag.select('day', 'hashtag', 'week').groupby('day', 'hashtag', 'week')\n",
    "                       .count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important aside concerning `count()`\n",
    "\n",
    "The use of `count()` here is very confusing -- in this case, `count()` is a method of a [GroupedData](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData) object, which performs a counting of items in each group. Our grouping here is defined by week, day, and hashtag, so calling `count()` gives us the number of times a hashtag appears each week. To make it even more confusing, `count()` in this case actually returns a `DataFrame`, with \"count\" as one of the columns. \n",
    "\n",
    "However, we are much more used to seeing `count()` as an RDD method! There, it returns the number of elements in the RDD, which is much different. See for example the line below, which uses `count()` as an RDD method and actually just returns the number of rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 58 ms, total: 202 ms\n",
      "Wall time: 11.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5221650"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time day_counts.sort('day').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----+-----+\n",
      "|day|    hashtag|week|count|\n",
      "+---+-----------+----+-----+\n",
      "|278|          n|  40|   20|\n",
      "|281|sougofollow|  41| 4567|\n",
      "|294|      sehun|  43|  345|\n",
      "|276|       baby|  40|  112|\n",
      "|288|         ff|  42| 3813|\n",
      "+---+-----------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "day_counts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same counting of daily occurences of each hashtag can be done with an RDD operation using a `map` and `reduceByKey`, though it might look a bit messier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_counts_rdd = daily_hashtag.rdd.map(lambda r: ((r.day, r.hashtag, r.week), 1)).reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 606 ms, sys: 231 ms, total: 837 ms\n",
      "Wall time: 33.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5221650"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time day_counts_rdd.sortBy(lambda ((day, hashtag, week), count): day).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame` API avoids shipping data back and forth to the Python intepreter (and can do some extra optimizations) so the performance difference can be significant, as we can see above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure that the results are the same by looking up a hashtag in both places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3238]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_counts_rdd.lookup((274,'retweet',40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-----+\n",
      "|day|hashtag|week|count|\n",
      "+---+-------+----+-----+\n",
      "|274|retweet|  40| 3238|\n",
      "+---+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "day_counts.filter((day_counts.hashtag == 'retweet') & (day_counts.day == 274)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should persist `day_counts` in memory since we'll be using it later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[day: int, hashtag: string, week: int, count: bigint]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_counts.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a quick idea of the most popular hashtags by looking at the weekly averages of daily hashtag counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+\n",
      "|week|             hashtag|        avg(count)|\n",
      "+----+--------------------+------------------+\n",
      "|  42|    emabiggestfans1d|54077.857142857145|\n",
      "|  42|emabiggestfansjus...| 52082.28571428572|\n",
      "|  44|    emabiggestfans1d|43656.833333333336|\n",
      "|  44|emabiggestfansjus...|41650.666666666664|\n",
      "|  43|        kcaargentina| 36302.28571428572|\n",
      "|  43|    emabiggestfans1d|30190.571428571428|\n",
      "|  43|emabiggestfansjus...| 29586.85714285714|\n",
      "|  42|        kcaargentina| 25964.14285714286|\n",
      "|  40|       votevampsvevo|           21236.0|\n",
      "|  41|    emabiggestfans1d| 19649.14285714286|\n",
      "|  41|emabiggestfansjus...| 19479.85714285714|\n",
      "|  41|        kcaargentina|19261.714285714286|\n",
      "|  44|        kcaargentina|16576.833333333332|\n",
      "|  40|        kcaargentina|           15295.0|\n",
      "|  42|         gameinsight| 14074.42857142857|\n",
      "|  41|         gameinsight|13817.714285714286|\n",
      "|  40|         gameinsight|           13668.8|\n",
      "|  43|         gameinsight| 12464.42857142857|\n",
      "|  42|             android|10360.714285714286|\n",
      "|  41|             android| 9980.142857142857|\n",
      "|  40|             android|            9867.4|\n",
      "|  44|         gameinsight| 9744.666666666666|\n",
      "|  43|             android| 9072.714285714286|\n",
      "|  40|onedirectionradio...|            8345.0|\n",
      "|  43|               by3_7|            8289.0|\n",
      "|  40|      followmecarter|            7964.0|\n",
      "|  44|             android| 7500.166666666667|\n",
      "|  42|        androidgames| 7359.857142857143|\n",
      "|  41|        androidgames| 7351.285714285715|\n",
      "|  40|        androidgames|            7197.6|\n",
      "|  43|        androidgames| 6925.714285714285|\n",
      "|  43|        laliesposito| 6911.285714285715|\n",
      "|  44|     babyonemoretime| 6745.833333333333|\n",
      "|  43|      gonzalohiguain| 6174.857142857143|\n",
      "|  40|      teamfollowback|            6157.6|\n",
      "|  43|                  rt| 6020.714285714285|\n",
      "|  42|      teamfollowback| 5946.428571428572|\n",
      "|  42|                  rt| 5872.857142857143|\n",
      "|  41|      teamfollowback| 5837.857142857143|\n",
      "|  43|      teamfollowback| 5777.285714285715|\n",
      "|  43|stealmygirlvideot...| 5762.333333333333|\n",
      "|  44|                  rt| 5712.333333333333|\n",
      "|  41|                  rt| 5602.571428571428|\n",
      "|  40|                  rt|            5490.4|\n",
      "|  44|      teamfollowback|            5489.0|\n",
      "|  40|                ipad|            5354.4|\n",
      "|  41|                ipad| 5344.142857142857|\n",
      "|  42|                ipad| 5297.571428571428|\n",
      "|  42|         sougofollow|            5113.0|\n",
      "|  44|        androidgames| 5053.833333333333|\n",
      "|  43|         sougofollow| 4942.428571428572|\n",
      "|  41|         sougofollow| 4831.714285714285|\n",
      "|  44|             wannabe| 4778.333333333333|\n",
      "|  40|           ipadgames|            4744.6|\n",
      "|  41|           ipadgames|            4735.0|\n",
      "|  42|           ipadgames|            4698.0|\n",
      "|  42|                  ff| 4651.857142857143|\n",
      "|  40|         sougofollow|            4645.0|\n",
      "|  43|                ipad|            4583.0|\n",
      "|  44|        sexylist2014|            4579.0|\n",
      "|  44|         sougofollow|            4442.5|\n",
      "|  40|                porn|            4432.8|\n",
      "|  44|           halloween| 4411.666666666667|\n",
      "|  44|      gonzalohiguain|           4402.25|\n",
      "|  43|stealmygirlvevore...| 4335.857142857143|\n",
      "|  41|                porn| 4335.428571428572|\n",
      "|  40|thankyou1dforthewwat|            4231.0|\n",
      "|  42|      gonzalohiguain| 4226.285714285715|\n",
      "|  41|  alwayssupportluhan|            4152.0|\n",
      "|  43|           ipadgames|            4080.0|\n",
      "|  44|                  ff|4049.3333333333335|\n",
      "|  40|              follow|            4020.0|\n",
      "|  44|                news|            4016.0|\n",
      "|  44|                ipad|            3986.0|\n",
      "|  43|              follow|3956.5714285714284|\n",
      "|  41|              follow|3938.4285714285716|\n",
      "|  43|                  ff|3885.1428571428573|\n",
      "|  43|     babyonemoretime|3883.5714285714284|\n",
      "|  42|              follow|            3822.0|\n",
      "|  42|                porn| 3793.714285714286|\n",
      "|  42|          followback| 3768.285714285714|\n",
      "|  40|          followback|            3723.2|\n",
      "|  41|          followback|3713.5714285714284|\n",
      "|  44|              follow|            3695.5|\n",
      "|  43|             wannabe| 3664.285714285714|\n",
      "|  43|         superjunior|3658.1428571428573|\n",
      "|  40|                mgwv|            3648.2|\n",
      "|  43|                mgwv|            3612.0|\n",
      "|  42|                love|3545.1428571428573|\n",
      "|  42|          openfollow|3536.1428571428573|\n",
      "|  40|         followtrick|            3519.8|\n",
      "|  40|     happy15thmarwah|            3510.0|\n",
      "|  43|          openfollow|3500.8571428571427|\n",
      "|  44|                porn|3470.6666666666665|\n",
      "|  41|          openfollow|            3448.0|\n",
      "|  41|         followtrick|3441.4285714285716|\n",
      "|  41|                mgwv|3428.5714285714284|\n",
      "|  44|           ipadgames|            3403.5|\n",
      "|  43|      orianasabatini|3402.1428571428573|\n",
      "|  41|         my1dwwafilm|            3392.0|\n",
      "+----+--------------------+------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "day_counts.groupBy('week', 'hashtag').avg('count').sort('avg(count)', ascending=False).show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the [MTV Europe Music Awards](https://en.wikipedia.org/wiki/2014_MTV_Europe_Music_Awards) happened in late 2014... (and [yet another boy band](https://en.wikipedia.org/wiki/One_Direction) is on the scene?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `window` functions\n",
    "\n",
    "### top daily hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets say we want to know the top tweets for each day. This is a non-trivial thing to try and compute using a standard RDD, but the `DataFrame` API gives us \"window\" functions that let us do it relatively easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_window = Window.partitionBy('day').orderBy(func.desc('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_rank = func.rank().over(daily_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------------+----+\n",
      "|day|count|      hashtag|rank|\n",
      "+---+-----+-------------+----+\n",
      "|274| 9880|  gameinsight|   1|\n",
      "|274| 9179| kcaargentina|   2|\n",
      "|274| 6675|      android|   3|\n",
      "|274| 5893| androidgames|   4|\n",
      "|274| 4618|           rt|   5|\n",
      "|275|13857| kcaargentina|   1|\n",
      "|275|13725|  gameinsight|   2|\n",
      "|275|10093|   1dproposal|   3|\n",
      "|275| 9774|      android|   4|\n",
      "|275| 7515| androidgames|   5|\n",
      "|276|15196|  gameinsight|   1|\n",
      "|276|14743| kcaargentina|   2|\n",
      "|276|11497|      android|   3|\n",
      "|276| 7423| androidgames|   4|\n",
      "|276| 6806|           ff|   5|\n",
      "|277|21738|votevampsvevo|   1|\n",
      "|277|19660| kcaargentina|   2|\n",
      "|277|15055|  gameinsight|   3|\n",
      "|277|11135|      android|   4|\n",
      "|277| 7401| androidgames|   5|\n",
      "+---+-----+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(day_counts.select('day', 'count', 'hashtag', daily_rank.alias('rank'))\n",
    "           .filter('rank < 6')\n",
    "           .show(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complicated example: calculating the daily standard deviation based on a weekly window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekly_window = Window.partitionBy('week', 'hashtag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_diff = day_counts['count'] - func.mean('count').over(weekly_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variance_arg = (1./7.)*mean_diff*mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_stats = (day_counts.withColumn('var_arg', variance_arg)\n",
    "                         .groupBy('week', 'hashtag')\n",
    "                         .sum('var_arg')\n",
    "                         .withColumn('stddev', func.sqrt('sum(var_arg)'))\n",
    "                         .sort('stddev', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+------------------+\n",
      "|week|             hashtag|        sum(var_arg)|            stddev|\n",
      "+----+--------------------+--------------------+------------------+\n",
      "|  41|    emabiggestfans1d| 5.615435298361732E8| 23696.90971068112|\n",
      "|  41|emabiggestfansjus...| 4.734708501219755E8|21759.385334194885|\n",
      "|  44|    emabiggestfans1d| 2.938166898330395E8|17141.081932977264|\n",
      "|  44|        kcaargentina| 2.910696484044708E8|17060.763417985458|\n",
      "|  44|emabiggestfansjus...|2.5634334961879125E8|16010.726080312263|\n",
      "|  43|emabiggestfansjus...|1.0385722155091654E8|10191.036333509785|\n",
      "|  43|    emabiggestfans1d| 9.939805853051284E7| 9969.857498004314|\n",
      "|  42|    emabiggestfans1d| 6.937371583666532E7| 8329.088535768204|\n",
      "|  42|emabiggestfansjus...| 5.286668506117162E7|7270.9480166737285|\n",
      "|  43|stealmygirlvevore...| 4.690633240811635E7|6848.8197821315425|\n",
      "|  44|  wildlifemusicvideo|2.6747042285687536E7| 5171.754275455045|\n",
      "|  42|        kcaargentina| 2.605941526528006E7| 5104.842335007033|\n",
      "|  41|        kcaargentina|1.8511706204063118E7| 4302.523236899845|\n",
      "|  40|      followmecarter| 1.804877257141052E7| 4248.384701437773|\n",
      "|  43|        followmenash|1.5861168693861688E7|3982.6082777322813|\n",
      "|  44|somethingbigishap...|1.5562684857127294E7|3944.9568891341887|\n",
      "|  44|           halloween|1.5092409619032523E7|3884.8950589472197|\n",
      "|  42|        camilasayshi|1.5042890678556383E7| 3878.516556437059|\n",
      "|  43|        kcaargentina|1.3614658775496589E7|3689.8047069589725|\n",
      "|  44|        laliesposito|1.2554940214273158E7| 3543.295106856492|\n",
      "+----+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "daily_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
